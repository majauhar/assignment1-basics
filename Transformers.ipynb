{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e66b06ff-d661-4676-9c39-143d3fb34a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39abe64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange, einsum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327f2f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 4])\n"
     ]
    }
   ],
   "source": [
    "D = torch.rand((4, 8, 4)) # batch, seq, dim\n",
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21fd28e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "A = torch.rand((4, 4)) # dim, dim\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a4d6c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 4])\n"
     ]
    }
   ],
   "source": [
    "Y = D @ A.T\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8e5751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 4])\n"
     ]
    }
   ],
   "source": [
    "Y_ = einsum(D, A, \"batch sequence d_in, d_out d_in -> batch sequence d_out\")\n",
    "print(Y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81043883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.equal(Y, Y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0cd0850-1188-4c90-853c-0ee2c623b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    # Python random module\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    # CUDA (if available)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # For multi-GPU\n",
    "        torch.backends.cudnn.deterministic = True  # Deterministic algorithms\n",
    "        torch.backends.cudnn.benchmark = False     # Disable auto-optimization\n",
    "\n",
    "set_seed(42)  # Call this at the start of your script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76d1c6ee-041d-4e1e-9c5f-6b8430652569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange, einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c931fcc8-aaf2-4f04-9cec-b7614ace79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.randn(64,128,128,3)\n",
    "dim_by = torch.linspace(start=0.0, end=1.0, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c138d10d-b232-47da-a332-2cdbd76724b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_by = dim_by.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20ad6368-2ff5-45f7-a683-018d67c8a737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_by.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0bda472-c999-40f7-b555-3347285cc6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_by = dim_by.unsqueeze(2).unsqueeze(3).unsqueeze(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12985641-5859-42ad-9bf2-6bd0290cfe58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_by.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80c576d0-ea7d-45f7-a8aa-bfa7d33f96a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9a4662e-1c2a-40ca-b06d-0680df1a0acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 128, 128, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68d54e86-1d52-475a-ad88-66f1905ea03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 128, 128, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimmed_images = images * dim_by\n",
    "dimmed_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db0526a6-e209-4e23-8b7f-2ebd9f40e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_last = torch.randn(64, 32, 32, 3)\n",
    "B = torch.randn(32*32, 32*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22945838-8a93-4127-bddf-2ccaa3a62e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_last_flat = channels_last.view(\n",
    "    -1, channels_last.size(1), channels_last.size(2), channels_last.size(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e6593a3-9a67-4c1b-b911-4c390c399882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32, 32, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels_last_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54ebcf3c-537f-4f31-b90f-775434eae08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(channels_last, channels_last_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66b64d76-a70e-4e50-8574-ebb7d76b3669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 1024])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd4e61f0-0362-492b-9de3-3a5a09a7adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_first_flat = channels_last_flat.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3889081a-7240-40dd-b2d2-ee711a973d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32, 32, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels_first_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9908dd2f-aceb-48a4-89e1-1de27c759059",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [2048, 3] but got: [2048, 1024].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m channels_first_flat_transformed \u001b[38;5;241m=\u001b[39m \u001b[43mchannels_first_flat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [2048, 3] but got: [2048, 1024]."
     ]
    }
   ],
   "source": [
    "channels_first_flat_transformed = channels_first_flat @ B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5a95c5f-fff7-40b2-b131-c9852cee3cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_last_flat = channels_last.view(\n",
    "    -1, channels_last.size(1) * channels_last.size(2), channels_last.size(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4852d18a-fb97-4ba7-9678-704c0fee2dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1024, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels_last_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "579c1634-7ac4-43d0-997f-a96ee5bbd187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 1024 3\n"
     ]
    }
   ],
   "source": [
    "print(*channels_last_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbf1eb1a-dd23-4aaf-aeac-b16c6ac1a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in = 24\n",
    "d_out = 32\n",
    "test_weight = torch.randn(d_in, d_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1686dfc6-90a7-4bad-b9ca-84c51cc7cf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0460,  0.4442, -1.4056, -0.1128,  0.2139,  0.5391, -0.5942,  1.8176,\n",
       "         0.4017,  0.6120,  2.4649,  0.7039, -0.2908,  0.4892, -0.1077,  1.3844,\n",
       "        -0.6630,  1.8973, -1.6479,  0.3498, -0.4356, -1.0734,  0.1763,  1.1610,\n",
       "        -1.8292,  0.6686,  0.5466,  0.7458, -1.6116, -1.9045,  0.7526, -0.1948])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51612d98-6737-4c70-872c-e086eb11c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "mean=0.\n",
    "std=math.sqrt(2./(d_in + d_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffcef12e-5c00-44bf-891b-b3c8608a7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weight = torch.nn.init.trunc_normal_(\n",
    "    test_weight,\n",
    "    mean=0,\n",
    "    std=std,\n",
    "    a=-3*std,\n",
    "    b=3*std\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "310f0867-0b25-402f-a3f7-5b5f3dfbd9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 32])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e790d273-d987-4fbe-9b6a-9c3b055a1246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5405, -0.1328, -0.0037,  0.2573, -0.0750, -0.0887, -0.2748, -0.0140,\n",
       "         0.1534, -0.2061,  0.3408, -0.1994, -0.0738,  0.1119, -0.1461,  0.0803,\n",
       "        -0.0132, -0.0212,  0.0859,  0.2477, -0.0278,  0.0524,  0.1449, -0.1900,\n",
       "        -0.2866,  0.0095, -0.0197,  0.0568, -0.2302,  0.1078, -0.1733,  0.1052])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43204d8-c3e1-407b-a133-13d98563bc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0be982d3-5970-43a3-aba6-9b620d387a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, device=None, dtype=None):\n",
    "        super(Linear, self).__init__()\n",
    "        # initiate a linear transformation module\n",
    "        data = torch.nn.init.trunc_normal_(\n",
    "            torch.randn(out_features, in_features, device=device, dtype=dtype),\n",
    "            mean=0,\n",
    "            std=math.sqrt(2./(in_features + out_features)),\n",
    "            a=-3*math.sqrt(2./(in_features + out_features)),\n",
    "            b=3*math.sqrt(2./(in_features + out_features))\n",
    "        )\n",
    "        self.weight = torch.nn.Parameter(data)\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        # vanilla pytorch way\n",
    "        # output1 = x @ self.weight.T\n",
    "        # einsum way\n",
    "        output = einsum(x, self.weight,\n",
    "                        \"batch seq d_in, d_out d_in -> batch seq d_out\"\n",
    "                       )\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f68e0e7-7da9-40e8-a5d1-b5aa1ad9d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.randn(8,16,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8b415348-1e8f-429b-b9fe-cce1d3edda20",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = Linear(32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "26b32c21-cb00-4399-84ef-b1372687c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = linear_layer(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "55c77325-045b-4c21-a3ec-b15a98a2c5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 64])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77cfa483-0916-4df6-afb2-49b4f98bbe53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a5297dea-6b4f-4457-a58d-087177051845",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(torch.nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, device=None, dtype=None):\n",
    "        super(Embedding, self).__init__()\n",
    "        data = torch.nn.init.trunc_normal_(\n",
    "            torch.randn(num_embeddings, embedding_dim, device=device, dtype=dtype),\n",
    "            mean=0,\n",
    "            std=1,\n",
    "            a=-3,\n",
    "            b=3\n",
    "        )\n",
    "        self.embeddings = torch.nn.Parameter(data)\n",
    "    def forward(self, token_ids: torch.Tensor) -> torch.Tensor:\n",
    "        output = self.embeddings[token_ids]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "69b1530f-b390-4cf4-8902-68c5727715ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = Embedding(32, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8bdc3308-5692-4313-b10a-b5125a339287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6969,  0.8193,  0.2542, -0.2801,  1.0709, -0.4859,  0.7410,  0.3139,\n",
       "         -0.1099, -2.8018,  0.1574, -0.7763,  0.8081,  1.3766, -0.5112, -1.1423],\n",
       "        [ 0.0933, -0.6333,  0.1861, -0.2137, -1.0431,  1.7421,  0.8766, -0.7102,\n",
       "          0.4819,  1.3366,  0.4977,  0.0891, -1.5155, -0.2780, -0.9904,  0.6207]],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.embeddings[torch.tensor([0, 1], dtype=torch.int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "85387aeb-6ac8-47ce-b27a-2ff11584767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.tensor([[1,4],[2,3]], dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "25fdd0e1-542d-456f-a23c-3efdf21aeb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = emb_model(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1f63c250-d760-4a77-bf12-a2d6be6b50e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 16])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = output * torch.ones(16)\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ad8da4a-d2d7-43ee-b01c-adb89c6489b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, eps: float = 1e-5, device=None, dtype=None):\n",
    "        super(RMSNorm, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.gain = torch.nn.Parameter(torch.randn(d_model, device=device, dtype=dtype))\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        in_dtype = x.dtype\n",
    "        x = x.to(torch.float32)\n",
    "        x_squared = x**2 + self.eps\n",
    "        x_mean = torch.mean(x_squared, dim=-1, keepdim=True)\n",
    "        x_rms = torch.sqrt(x_mean)\n",
    "        x /= x_rms\n",
    "        result = x * self.gain\n",
    "        return result.to(in_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e58f38a-be33-40c9-a59a-2503a0bb8ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_norm = RMSNorm(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a633e58e-10e2-42c4-859f-a846c12b9a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Parameter.size>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms_norm.gain.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b3fb6530-0d49-4802-8c5f-4a890bd646e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.randn(2, 2, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7ac1f709-bbf3-4334-af38-4de85018dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = rms_norm(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "17210727-7e75-4ff6-9f3f-1289101c3ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 32])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fba0367e-f909-41db-a3d7-e0ba9624609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotaryPositionalEmbedding(torch.nn.Module):\n",
    "    def __init__(self, theta: float, d_k: int, max_seq_len: int, device=None):\n",
    "        super(RotaryPositionalEmbedding, self).__init__()\n",
    "        position = torch.arange(max_seq_len, device=device)\n",
    "        dim_range = torch.arange(0, d_k, 2, device=device).float()\n",
    "\n",
    "        freq = 1.0 / (theta**(dim_range/d_k))\n",
    "        thetas = torch.outer(position, freq)\n",
    "\n",
    "        self.register_buffer(\"freqs\", torch.outer(position, freq))\n",
    "        self.register_buffer(\"cos_cache\", torch.cos(thetas))\n",
    "        self.register_buffer(\"sin_cache\", torch.sin(thetas))\n",
    "\n",
    "    def forward(self, x: torch.tensor, token_positions: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (..., seq_len, d_k)\n",
    "            token_positions: (..., seq_len)\n",
    "        Returns:\n",
    "            Tensor: (..., seq_len, d_k)\n",
    "        \"\"\"\n",
    "        seq_len = x.size(-2)\n",
    "        cos = self.cos_cache[token_positions]\n",
    "        sin = self.sin_cache[token_positions]\n",
    "        \n",
    "        x1, x2 = x.chunk(2, dim=-1)\n",
    "        rotated = torch.cat(\n",
    "            (x1 * cos - x2 * sin,\n",
    "             x2 * cos + x1* sin),\n",
    "            dim=-1\n",
    "        )\n",
    "        return rotated\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d7187ab6-920f-4e24-8cd6-2de80cacb22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rope = RotaryPositionalEmbedding(theta=10000.0, d_k=4, max_seq_len=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "11fa8f69-fa6b-4b0c-b19a-28197b78ca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(4, 3, 4)\n",
    "positions = torch.tensor([2,3,4], dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "83569fc2-abb9-4225-9227-cb0edc0e5c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = rope(x, positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d46b6bdf-99e5-4239-989d-4564b545db94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4602dead-69f3-400d-9fdd-7248a23437e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3254,  0.9798,  0.4932,  1.0198],\n",
       "        [-1.1311,  0.9696, -0.8489,  1.0295],\n",
       "        [ 0.1032,  0.9592, -1.4104,  1.0392]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "52b2b3a9-27d8-407c-83f8-efe92d667e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = x.chunk(2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "dcb68999-cc07-4441-a68c-d796da8822c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "85128dfa-397f-450e-84c8-603445d2bd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.]]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_vals = x.max(dim=2, keepdim=True).values\n",
    "max_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "2ac3686c-6036-4a71-aa85-a7d5df4b1c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted_exp = torch.exp(x - max_vals)\n",
    "shifted_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6d798f8b-cec7-4760-8936-f63984753b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.],\n",
       "         [4.],\n",
       "         [4.]],\n",
       "\n",
       "        [[4.],\n",
       "         [4.],\n",
       "         [4.]],\n",
       "\n",
       "        [[4.],\n",
       "         [4.],\n",
       "         [4.]],\n",
       "\n",
       "        [[4.],\n",
       "         [4.],\n",
       "         [4.]]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_exp = shifted_exp.sum(dim=2, keepdim=True)\n",
    "sum_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "6e9e1bb7-bc2c-4d8f-8653-c157310935a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500]],\n",
       "\n",
       "        [[0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500]],\n",
       "\n",
       "        [[0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500]],\n",
       "\n",
       "        [[0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500]]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_output = shifted_exp / sum_exp\n",
    "softmax_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "94c27902-abe3-4e2d-869f-23c649e07b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: torch.Tensor, dimension: int) -> torch.Tensor:\n",
    "    max_vals = torch.max(x, dim=dimension, keepdim=True).values\n",
    "    shifted_exp = torch.exp(x - max_vals)\n",
    "    sum_exp = shifted_exp.sum(dim=dimension, keepdim=True)\n",
    "    softmax_output = shifted_exp / sum_exp\n",
    "    return softmax_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d0a49c9f-0d98-4716-bf9d-403815ba9ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([1, 1])\n",
    "t.size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "0d67d439-4474-4cb8-bb77-70f737dfb332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 0.5000])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_output = softmax(t, dimension=0)\n",
    "softmax_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "45781e17-7c9b-4e7c-bd68-78e7a622cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(\n",
    "    Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor, mask: torch.Tensor=None\n",
    "):\n",
    "    \"\"\"\n",
    "        Q: batch_size, ..., seq_len, d_k\n",
    "        K: batch_size, ..., seq_len, d_k\n",
    "        V: batch_size, ..., seq_len, d_v\n",
    "        mask: (seq_len, seq_len)\n",
    "        returns: (batch_size, ..., d_v)\n",
    "    \"\"\"\n",
    "    d_k = Q.size(-1)\n",
    "    # Dot product\n",
    "    # attention = Q @ K.transpose(-2,-1)\n",
    "    attention = einsum(Q, K,\n",
    "                       \"batch_size ... seq_len_q d_q, batch_size ... seq_len_k d_k -> batch_size ... seq_len_q seq_len_k\")\n",
    "    attention_scaled = attention / torch.sqrt(torch.Tensor([d_k]))\n",
    "    if mask is not None:\n",
    "        attention_scaled = attention_scaled.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "    attention_weights = softmax(attention_scaled, dimension=-1)\n",
    "    attention_output = einsum(attention_weights, V,\n",
    "                              \"batch_size ... seq_len_q seq_len_k, batch_size ... seq_len_v d_v -> batch_size ... seq_len_q d_v\"\n",
    "                             )\n",
    "    return attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "2843bb96-fe50-4b5e-95dc-69e31554ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example parameters\n",
    "batch_size = 2\n",
    "seq_len = 5\n",
    "d_k = 64\n",
    "d_v = 64\n",
    "\n",
    "# Create random tensors\n",
    "query = torch.randn(batch_size, seq_len, d_k)\n",
    "key = torch.randn(batch_size, seq_len, d_k)\n",
    "value = torch.randn(batch_size, seq_len, d_v)\n",
    "\n",
    "# Create attention mask (optional)\n",
    "mask = torch.ones(batch_size, seq_len, seq_len)\n",
    "mask[:, :, -2:] = 0  # Mask last two positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "8ba1f84c-5c40-401b-9c41-77d776dab6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 64])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f3761c64-9476-4b39-ae23-20338bd5fce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product = einsum(query, key,\n",
    "                     \"batch_size ... seq_len_q d_q, batch_size ... seq_len_k d_k -> batch_size ... seq_len_q seq_len_k\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "c72c15be-89dd-4a04-9eca-8a80b687a005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 5])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "a4af3cef-d40c-4ae6-a710-47ad8b5a13be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 5])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "270f9adb-83a0-4d69-9ac8-3acf578071bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = scaled_dot_product_attention(query, key, value, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "fb4a51b5-f2be-4b5e-8adb-e7fe316264eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 64])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "4674dd81-326b-424b-a862-b002e9ec8f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 7])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key.transpose(-2,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "fb33b51d-6e27-4a23-b8c3-3bb3cf0a6b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 64])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "8d91d51e-4840-46d2-98ed-41c43436cfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6832, -1.6233],\n",
       "        [ 1.5669,  1.0561],\n",
       "        [ 1.1985, -0.2246]])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,3,2)\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "afe9fc0c-79cc-4067-ae9a-a161b295f95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3, 2])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.stack([x]*3, dim=-2)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "a70b3eb2-4c03-4869-8dd8-a495ba7178ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rearrange(x,\n",
    "           \"... a b c -> ... (a b) c\"\n",
    "          )\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "304c4eb2-7956-4908-a5eb-fe2f72f6dd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9364,  0.9364,  0.9364],\n",
       "        [-1.8515, -1.8515, -1.8515],\n",
       "        [-0.3825, -0.3825, -0.3825],\n",
       "        [-0.8591, -0.8591, -0.8591],\n",
       "        [-0.2684, -0.2684, -0.2684],\n",
       "        [ 1.1453,  1.1453,  1.1453]])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "b2cfcd04-7b95-495b-befd-d3e868be45ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = int(d_model / num_heads)\n",
    "        self.W_q = Linear(d_model, d_model)\n",
    "        self.W_k = Linear(d_model, d_model)\n",
    "        self.W_v = Linear(d_model, d_model)\n",
    "        self.W_o = Linear(d_model, d_model)\n",
    "        self.rope = RotaryPositionalEmbedding(theta=10000.0, d_k=self.d_k, max_seq_len=256)\n",
    "    def forward(self, x: torch.Tensor, apply_mask: bool= True):\n",
    "        seq_len = x.size(-2)\n",
    "        if apply_mask:\n",
    "            mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
    "            mask = ~mask\n",
    "        query = self.W_q(x) # batch_size seq_len d_model\n",
    "        key = self.W_k(x)\n",
    "        value = self.W_v(x)\n",
    "        ## rearrange\n",
    "        query = rearrange(query,\n",
    "                          \"... seq_len (h d_k) -> ... h seq_len d_k\",\n",
    "                          h=self.num_heads, d_k=self.d_k\n",
    "                         )\n",
    "        key = rearrange(key,\n",
    "                          \"... seq_len (h d_k) -> ... h seq_len d_k\",\n",
    "                          h=self.num_heads, d_k=self.d_k\n",
    "                         )\n",
    "        value = rearrange(value,\n",
    "                          \"... seq_len (h d_k) -> ... h seq_len d_k\",\n",
    "                          h=self.num_heads, d_k=self.d_k\n",
    "                         )\n",
    "        query = rope(query, token_positions=torch.arange(seq_len))\n",
    "        key = rope(query, token_positions=torch.arange(seq_len))\n",
    "        attention_values = scaled_dot_product_attention(query, key, value, mask=mask)\n",
    "        \n",
    "        attention_values = rearrange(attention_values,\n",
    "                                     \"batch h seq_len d_k -> batch seq_len (h d_k)\",\n",
    "                                     h=int(self.num_heads), d_k=int(self.d_k)\n",
    "                                    )\n",
    "        return self.W_o(attention_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "ae8832f3-e5cd-4b6f-9906-030eaa17894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "seq_len = 3\n",
    "d_model = 12\n",
    "h = 4\n",
    "d_k = 3\n",
    "\n",
    "Q = torch.randn(batch_size, seq_len, d_model)\n",
    "K = torch.randn(batch_size, seq_len, d_model)\n",
    "V = torch.randn(batch_size, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "75e50ebf-fff0-4af5-bfb5-9a12f52c0421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(d_model / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "2823d5a4-0c96-4cd2-80d3-51f114aba5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadSelfAttention(d_model, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "f4d605aa-2d4d-4782-9ffe-1f903cf10387",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights = mha(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "ce382ea3-ab1b-4ad8-80b1-e33e62d8f930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 12])"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "90eb56ef-c988-4771-8b38-13fcbf812d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights = rearrange(attention_weights,\n",
    "                              \"b h seq_len d_k -> b seq_len (h d_k)\",\n",
    "                              h=h, d_k=d_k\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "3aa7273f-74b0-4a87-a103-8fad0bd2ae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = Q.view(batch_size, seq_len, h, d_k).transpose(1, 2)\n",
    "Q_ = rearrange(Q,\n",
    "               \"... seq_len (h d_k) -> ... h seq_len d_k\",\n",
    "               h=h, d_k=d_k\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "2c5058bb-4243-4c05-9597-1a44851977f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights = rearrange(attention_weights,\n",
    "                           \"b h s d_k -> b s (h d_k)\",\n",
    "                           b=batch_size, h=4, d_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "4b9f0488-5e7b-423d-b0fe-03aed452dc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(Q1, Q_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "bac52245-c780-49e1-8508-d999f699337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = {\n",
    "            \"answerKey\": \"B\",\n",
    "            \"choices\": {\n",
    "                \"label\": [\"A\", \"B\", \"C\", \"D\"],\n",
    "                \"text\": [\"Shady areas increased.\", \"Food sources increased.\", ...]\n",
    "            },\n",
    "            \"question\": \"...Which best explains why there were more chipmunks the next year?\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "d3d47170-14c6-4c11-8047-3056a1dcd49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = record[\"choices\"][\"label\"]\n",
    "choices = record[\"choices\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "8126d354-7637-44b4-b17c-90eb2ee04c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "35c56ed5-8ee8-435f-827e-16e863213590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord(\"A\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
